---
title: 대피소 csv파일 제작과정
date: 2023-10-14 15:19:10 +/-0800
categories: [Project Insights, Beacon]
tags: project    # TAG names should always be lowercase
---

사용자가 위치한 지역에 가까운 대피소를 클라이언트에 전송하기 위해 각 재난대피소 위치에 대한 CSV파일이 필요했다. 하지만 민방위 CSV파일 말고는 존재하지 않았다. 그래서 직접 CSV파일을 만들어본 경험을 적어본다.

### 문제 발생

https://www.safekorea.go.kr/idsiSFK/neo/main/main.html

이 사이트에 여러개가 존재한다.

![](/assets/img/csv/image.png)

그중 필요한건 이재민임시주거시설, 지진옥외대피소이고, 안타깝게도 전체를 가져오는 건 불가능해 보인다.

![](/assets/img/csv/image%20copy.png)

최소 시도선택과 시군구 선택 후 검색을 눌러야지 가져오는 걸로 보인다.(api요청할 때 그렇게 하도록 한 듯)

![](/assets/img/csv/image%20copy%202.png)

요청헤더를 보면

![](/assets/img/csv/image%20copy%203.png)

다음 url을 get요청하면 문제없이 가져오는 것을 postman으로 확인을 하였다. (다행히 요청헤더에 추가적인 설정은 필요 없어 보인다)

![](/assets/img/csv/image%20copy%204.png)

그렇다면 이 api를 하나하나 얻기 위해 시도선택 후 시군구 선택 하고 api를 갖고 오고 그 api를 요청해서 내가 수기로 직접 csv를 작성해야 하나 생각을 해봤다.

아무리 봐도 불가능할 거 같아 크롤링이 웹사이트 내에 웹사이트를 들어가 긁어올 수 있다는 개념을 본 기억이 있어 gpt4(뤼튼이용)한테 url을 전달하면 크롤링 역할을 수행할 수 있겠냐고 물어봤지만 불가능하다는 대답이 날아왔다..

### 내가 생각한  대안

<b>크롤링</b>

어차피 크롤링 코드를 짤 필요가 없는 게 데이터만 싹 다 긁어오는 게 목적이라 계속 운용할 필요가 없기 때문에 이미 크롤링 봇으로 나와 있는 걸 찾아봄
그중 scrapestorm이라는 게 무료로 가능하다 해서 해봤다.

![](/assets/img/csv/image%20copy%205.png)

그런데 잘 안된다. 지역구분 시도선택이 안 눌러짐. 억지로 이거 이용해서 겨우겨우 하는 것보다 내가 수기로 작성하는 게 더 빠를지도 모르겠다는 트레이드오프를 고려함

일단 api를 가져오는 게 목적이고 그 api를 통해 데이터를 불러오는 게 필요하다. gpt한테 물어봤다.

![](/assets/img/csv/image%20copy%206.png)

돌아오는 답변은

![](/assets/img/csv/image%20copy%207.png)

파이썬 코드를 알려줬고 실행해 보니 가져오는 듯하여 csv파일로 변환을 하는 코드로 작성해 달라 했다.

![](/assets/img/csv/image%20copy%208.png)

다행히 잘 작성해 줬고 실행해 보니 필요한 부분을 가져온다.

이제 이 파이썬 코드를 잘 활용하면 될 거 같은데 url을 보니 `https://www.safekorea.go.kr/idsiSFK/neo/ext/json/acmdfcltyList/acmdfcltyList_` 은 똑같고 뒤에 숫자만 다른 걸 보았다. 왠지 지역코드 느낌이 나서 인터넷에 검색해보니, https://jamdol.tistory.com/91 해당 사이트에서 나온 코드와 똑같고 시군구 코드였다는 걸 알게 되었다.

이제 gpt한테 학습을 시키면 알아서 코드를 작성해주지 않을까 하고 이런 식으로 알려줘 봤다.

"https://www.safekorea.go.kr/idsiSFK/neo/ext/json/acmdfcltyList/acmdfcltyList_{시군구 코드}.json"

결과적으로 파이썬에 코드를 돌려보니 정상적으로 csv 파일을 완성할 수 있게 되었다!

![](/assets/img/csv/image%20copy%209.png)

다음은 지진옥외대피소도 해야 했는데 또 이런 식으로 학습하려니 골치가 아팠다.

url 패턴을 보니

`https://www.safekorea.go.kr/idsiSFK/neo/ext/json/outhouseList/outhouseList_11680.json`

이런 식이고 acmdfcltyList 에서 outhouseList 으로 바뀜을 알 수가 있었다. 

그래서 메모장에서 모두 단어 바꾸기로 outhouseList 로 대체하고 파이썬 코드를 돌려보니 csv파일을 쉽게 얻을 수 있었다. 다행히 url패턴이 규칙대로 만들어져서 편하게 쓸 수 있었다.

